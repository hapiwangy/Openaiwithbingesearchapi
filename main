import logging

import azure.functions as func
import openai
import json
import requests

openai.api_version = "<model-version-with-function calling available>"
openai.api_type = "azure"
openai.api_key = "<your-key>"
openai.api_base = "<your-endpoint>"
subscription_key = "<your-bingsearch-key>" # bing search key


def do_the_research(context: str):
    print("sereaching online")
    search_url = "https://api.bing.microsoft.com/v7.0/search"
    headers = {"Ocp-Apim-Subscription-Key": subscription_key}
    params = {"q": context, "textDecorations": True, "textFormat": "HTML"}
    results = requests.get(search_url, headers=headers, params=params)
    response = ""
    results = json.loads(results.text)
    for para in results['webPages']['value']:
        try : 
            response += para['snippet']
        except:
            pass
    return json.dumps({"response": response})
def main(req: func.HttpRequest) -> func.HttpResponse:
    logging.info('Python HTTP trigger function processed a request.')

    content = req.params.get('content')
    if not content:
        try:
            req_body = req.get_json()
        except ValueError:
            pass
        else:
            content = req_body.get('content')
    messages = [{"role":"user", "content": f"{content}"}]
    functions = [
        {
            "name" : "do_the_research",
            "description" : "if you do not know , not sure,  can not answer, or can not give a normal response to the prompt",
            "parameters" : {
                "type" : "object",
                "properties": {
                    "context" : {
                        "type" : "string",
                        "description": "everything in the sentence",
                    },
                },
                "required" : ["context"],
            }
        }
    ]
    response = openai.ChatCompletion.create(
        engine="gpt-35-turbo",
        messages=messages,
        functions=functions,
        function_call="auto",
    )
    try : 
        response_message = response["choices"][0]["message"]
    except :
        response_message = response["choices"][0]["content"]
    print('here')
    # Step 2: check if GPT wanted to call a function
    if response_message.get("function_call"):
        available_functions = {
            "do_the_research" : do_the_research,
        }
        function_name = response_message["function_call"]['name']
        function_to_call = available_functions[function_name]
        function_args = json.loads(response_message["function_call"]["arguments"])
        function_response = function_to_call(
            # context = function_args['context'],
            **function_args
        )
        print(function_response)
        # Step 4: send the info on the function call and function response to GPT
        # messages.append(        
        # {
        #     "role": "user",
        #     "name": function_response["function_call"]["name"],
        #     "content": function_response["function_call"]["arguments"],
        # }
        # )  # extend conversation with assistant's reply
        messages.append(
            {
                "role": "function",
                "name": function_name,
                "content": function_response,
            }
        )  # extend conversation with function response
        second_response = openai.ChatCompletion.create(
            engine="gpt-35-turbo",
            messages=messages,
        )  # get a new response from GPT where it can see the function response
        print(second_response["choices"][0]["message"]["content"])
        return func.HttpResponse(second_response["choices"][0]["message"]["content"])
    else :
        print("without searching online")
        return func.HttpResponse(response_message["content"])
